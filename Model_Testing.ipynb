{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import keras.backend as K\n",
    "from tensorflow import keras\n",
    "from keras.layers import Reshape, Conv2DTranspose, PReLU\n",
    "from keras.utils import to_categorical, plot_model\n",
    "from keras.layers import Concatenate\n",
    "import numpy as np\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from tensorflow.image import resize\n",
    "from scipy.linalg import sqrtm\n",
    "import tensorflow as tf\n",
    "from IPython.display import clear_output, HTML\n",
    "import glob\n",
    "from keras.layers import AveragePooling2D, ZeroPadding2D, BatchNormalization, Activation, MaxPool2D, Add\n",
    "from keras.layers import Normalization, Dense, Conv2D, Dropout, BatchNormalization, ReLU\n",
    "from keras.models import Sequential, Model\n",
    "from keras import Input\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.layers import LeakyReLU, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from skimage.transform import AffineTransform, warp\n",
    "from keras import Sequential, Model\n",
    "from keras.layers import Dense, Conv2D, Reshape, UpSampling2D, \\\n",
    "    BatchNormalization, Activation, Input, LeakyReLU, ZeroPadding2D, Dropout, Flatten, Conv2DTranspose\n",
    "from keras.optimizers import Adam\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from scipy.ndimage import rotate\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Reshape, UpSampling2D, Conv2D, BatchNormalization, Activation, Input, LeakyReLU\n",
    "from keras.initializers import RandomNormal\n",
    "from numpy import expand_dims\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "from numpy.random import randn\n",
    "from numpy.random import randint\n",
    "from keras.datasets.fashion_mnist import load_data\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Conv2DTranspose\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import Dropout\n",
    "#import necessary libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from keras.preprocessing import image\n",
    "import keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "# import cv2\n",
    "# from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import expand_dims\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "from numpy.random import randn\n",
    "from numpy.random import randint\n",
    "from keras.datasets.fashion_mnist import load_data\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Conv2D, Conv2DTranspose\n",
    "from keras.layers import LeakyReLU, Dropout, Embedding, Concatenate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List physical GPUs and set memory growth\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file into a pandas DataFrame\n",
    "df = pd.read_csv('emnist-letters-train.csv', delimiter=',', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[0] != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the mapping dictionary\n",
    "mapping = {1: 97, 2: 98, 3: 99, 4: 100, 5: 101, 6: 102, 7: 103, 8: 104, 9: 105, \n",
    "           10: 106, 11: 107, 12: 108, 13: 109, 14: 110, 15: 111, 16: 112, 17: 113, \n",
    "           18: 114, 19: 115, 20: 116, 21: 117, 22: 118, 23: 119, 24: 120, 25: 121, \n",
    "           26: 122, 27: 123}\n",
    "\n",
    "        # Map the labels column to its corresponding value\n",
    "df[0] = df[0].map(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pre = np.array(df.iloc[:,0].values)\n",
    "y_pre = pd.Categorical(y_pre)\n",
    "X = np.array(df.iloc[:,1:].values)\n",
    "X = X.reshape(-1,28,28,1)\n",
    "preprocessed = []\n",
    "for image in X:\n",
    "    rotated_image = rotate(image, 90, reshape=False)\n",
    "    flipped_image = np.flipud(rotated_image)\n",
    "    preprocessed.append(flipped_image)\n",
    "X_pre = np.array(preprocessed)\n",
    "X_train,X_test,y_train,y_test = train_test_split(X_pre,y_pre,test_size=0.1,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(self, images, labels_input, epochs=10000, batch_size=256, save_interval=500, gen_steps=1):\n",
    "        os.makedirs('ACGAN_Generated_Images', exist_ok=True)\n",
    "        X_train = images\n",
    "        y_train = labels_input\n",
    "\n",
    "        batches_per_epoch = X_train.shape[0] // batch_size\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            for batch in range(batches_per_epoch):\n",
    "                # Train Discriminator\n",
    "                idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "                imgs = X_train[idx]\n",
    "                labels_real = np.ones((batch_size, 1))  # Real labels\n",
    "\n",
    "                noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "                gen_labels = np.random.randint(0, self.num_classes, (batch_size, 1))\n",
    "                gen_imgs = self.generator.predict([noise, gen_labels])\n",
    "                labels_fake = np.zeros((batch_size, 1))  # Fake labels\n",
    "\n",
    "                d_loss_real = self.discriminator.train_on_batch(imgs, [labels_real, y_train[idx]])\n",
    "                d_loss_fake = self.discriminator.train_on_batch(gen_imgs, [labels_fake, gen_labels])\n",
    "                d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "                # Train Generator\n",
    "                g_loss = None\n",
    "                for _ in range(gen_steps):\n",
    "                    noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "                    gen_labels = np.random.randint(0, self.num_classes, (batch_size, 1))\n",
    "                    valid_y = np.ones((batch_size, 1))\n",
    "                    g_loss = self.acgan.train_on_batch([noise, gen_labels], [valid_y, gen_labels])\n",
    "\n",
    "                # Print the progress\n",
    "                print(f\"Epoch {epoch + 1}/{epochs}, Batch {batch + 1}/{batches_per_epoch} [D loss: {d_loss[0]}, acc.: {100 * d_loss[3]:.2f}%] [G loss: {g_loss[0]}]\")\n",
    "\n",
    "            # Save generated images at save intervals\n",
    "            if (epoch + 1) % save_interval == 0:\n",
    "                self.save_images(epoch+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CGAN():\n",
    "\n",
    "    def __init__(self, rows, cols, channels, z = 100):\n",
    "        # Input shape\n",
    "        self.img_rows = rows\n",
    "        self.img_cols = cols\n",
    "        self.channels = channels\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        self.latent_dim = z\n",
    "        self.classes = 25\n",
    "        optimizer = Adam(0.00002, 0.5)\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.define_discriminator(self.img_shape,self.classes)\n",
    "        self.discriminator.compile(loss='binary_crossentropy',optimizer=optimizer,metrics=['accuracy'])\n",
    "        # Build the generator\n",
    "        self.g_model = self.define_generator(self.latent_dim,self.classes)\n",
    "        # The generator takes noise as input and generates imgs\n",
    "        z = Input(shape=(self.latent_dim,))\n",
    "        img = self.g_model(z)\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "        # The discriminator takes generated images as input and\n",
    "        # determines validity\n",
    "        valid = self.discriminator(img)\n",
    "        # The combined model (stacked generator and discriminator)\n",
    "        # Trains the generator to fool the discriminator\n",
    "        self.combined = Model(z, valid)\n",
    "        self.combined.compile(loss='binary_crossentropy',optimizer=optimizer)\n",
    "\n",
    "    # define the standalone discriminator model\n",
    "    def define_discriminator(self, in_shape, n_classes=25):\n",
    "        in_label = Input(shape=(1,))\n",
    "        li = Embedding(n_classes, 50)(in_label)\n",
    "        n_nodes = in_shape[0] * in_shape[1]\n",
    "        li = Dense(n_nodes)(li)\n",
    "        li = Reshape((in_shape[0], in_shape[1], 1))(li)\n",
    "        in_image = Input(shape=in_shape)\n",
    "        merge = Concatenate()([in_image, li])\n",
    "        fe = Conv2D(128, (3,3), strides=(2,2), padding='same')(merge)\n",
    "        fe = LeakyReLU(alpha=0.2)(fe)\n",
    "        fe = Conv2D(128, (3,3), strides=(2,2), padding='same')(fe)\n",
    "        fe = LeakyReLU(alpha=0.2)(fe)\n",
    "        fe = Flatten()(fe)\n",
    "        fe = Dropout(0.4)(fe)\n",
    "        out_layer = Dense(1, activation='sigmoid')(fe)\n",
    "        model = Model([in_image, in_label], out_layer)\n",
    "        return model\n",
    "\n",
    "    # define the standalone generator model\n",
    "    def define_generator(self, latent_dim, n_classes):\n",
    "        in_label = Input(shape=(1,))\n",
    "        li = Embedding(n_classes, 50)(in_label)\n",
    "        n_nodes = 7 * 7\n",
    "        li = Dense(n_nodes)(li)\n",
    "        li = Reshape((7, 7, 1))(li)\n",
    "        in_lat = Input(shape=(latent_dim,))\n",
    "        n_nodes = 128 * 7 * 7\n",
    "        gen = Dense(n_nodes)(in_lat)\n",
    "        gen = LeakyReLU(alpha=0.2)(gen)\n",
    "        gen = Reshape((7, 7, 128))(gen)\n",
    "        merge = Concatenate()([gen, li])\n",
    "        gen = Conv2DTranspose(64, (4,4), strides=(2,2), padding='same')(merge)\n",
    "        gen = LeakyReLU(alpha=0.2)(gen)\n",
    "        gen = Conv2DTranspose(64, (4,4), strides=(2,2), padding='same')(gen)\n",
    "        gen = LeakyReLU(alpha=0.2)(gen)\n",
    "        out_layer = Conv2D(1, (7,7), activation='tanh', padding='same')(gen)\n",
    "        model = Model([in_lat, in_label], out_layer)\n",
    "        return model\n",
    "\n",
    "    # define the combined generator and discriminator model, for updating the generator\n",
    "    def define_gan(self, g_model, d_model):\n",
    "        d_model.trainable = False\n",
    "        gen_noise, gen_label = g_model.input\n",
    "        gen_output = g_model.output\n",
    "        gan_output = d_model([gen_output, gen_label])\n",
    "        model = Model([gen_noise, gen_label], gan_output)\n",
    "        opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "        model.compile(loss='binary_crossentropy', optimizer=opt)\n",
    "        return model\n",
    "\n",
    "    def load_real_samples(self):\n",
    "        trainX, trainy = X_pre, y_pre\n",
    "        X = expand_dims(trainX, axis=-1)\n",
    "        X = X.astype('float32')\n",
    "        X = (X - 127.5) / 127.5\n",
    "        return [X, trainy]\n",
    "\n",
    "    # select real samples\n",
    "    def generate_real_samples(self, dataset, n_samples):\n",
    "        images, labels = dataset\n",
    "        ix = randint(0, images.shape[0], n_samples)\n",
    "        X, labels = images[ix], labels[ix]\n",
    "        y = ones((n_samples, 1))\n",
    "        return [X, labels], y\n",
    "\n",
    "    # generate points in latent space as input for the generator\n",
    "    def generate_latent_points(self, latent_dim, n_samples, n_classes=26):\n",
    "        x_input = randn(latent_dim * n_samples)\n",
    "        z_input = x_input.reshape(n_samples, latent_dim)\n",
    "        labels = randint(0, n_classes, n_samples)\n",
    "        return [z_input, labels]\n",
    "\n",
    "    # use the generator to generate n fake examples, with class labels\n",
    "    def generate_fake_samples(self, generator, latent_dim, n_samples):\n",
    "        z_input, labels_input = generate_latent_points(latent_dim, n_samples)\n",
    "        images = generator.predict([z_input, labels_input])\n",
    "        y = zeros((n_samples, 1))\n",
    "        return [images, labels_input], y\n",
    "\n",
    "    # function to save generated images\n",
    "    def save_imgs(self, generator, latent_dim, epoch):\n",
    "        r, c = 5, 5\n",
    "        z_input, labels_input = generate_latent_points(latent_dim, r * c)\n",
    "        gen_imgs = generator.predict([z_input, labels_input])\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
    "                axs[i,j].axis('off')\n",
    "                cnt += 1\n",
    "        os.makedirs('CGAN_Generated_Mnist', exist_ok=True)\n",
    "        fig.savefig(\"CGAN_Generated_Mnist/CGAN_mnist_{:d}.png\".format(epoch))\n",
    "        plt.close()\n",
    "\n",
    "    # train the generator and discriminator\n",
    "    def train(self, g_model, d_model, gan_model, dataset, latent_dim, n_epochs=100, n_batch=128):\n",
    "        bat_per_epo = int(dataset[0].shape[0] / n_batch)\n",
    "        half_batch = int(n_batch / 2)\n",
    "        for epoch in range(n_epochs):\n",
    "            [X_real, labels_real], y_real = generate_real_samples(dataset, half_batch)\n",
    "            d_loss1, _ = d_model.train_on_batch([X_real, labels_real], y_real)\n",
    "            [X_fake, labels], y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
    "            d_loss2, _ = d_model.train_on_batch([X_fake, labels], y_fake)\n",
    "            [z_input, labels_input] = generate_latent_points(latent_dim, n_batch)\n",
    "            y_gan = ones((n_batch, 1))\n",
    "            g_loss = gan_model.train_on_batch([z_input, labels_input], y_gan)\n",
    "            # print('>%d, %d/%d, d1=%.3f, d2=%.3f g=%.3f' % (i+1, j+1, bat_per_epo, d_loss1, d_loss2, g_loss))\n",
    "            print (\"%d [D1 loss: %.3f:%.3f,  acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss1,d_loss2,100*d_loss1, g_loss))\n",
    "        if n_epochs % 50 == 0:\n",
    "            save_imgs(g_model, latent_dim, epoch)\n",
    "        g_model.save('CGAN_generator.h5')\n",
    "\n",
    "    # size of the latent space\n",
    "    gan_model = define_gan(g_model, d_model)\n",
    "    dataset = load_real_samples()\n",
    "    train(g_model, d_model, gan_model, dataset, latent_dim)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
