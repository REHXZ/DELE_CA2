{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import keras.backend as K\n",
    "from tensorflow import keras\n",
    "from keras.layers import Reshape, Conv2DTranspose, PReLU\n",
    "from keras.utils import to_categorical, plot_model\n",
    "from keras.layers import Concatenate\n",
    "import numpy as np\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from tensorflow.image import resize\n",
    "from scipy.linalg import sqrtm\n",
    "import tensorflow as tf\n",
    "from IPython.display import clear_output, HTML\n",
    "import glob\n",
    "from keras.layers import AveragePooling2D, ZeroPadding2D, BatchNormalization, Activation, MaxPool2D, Add\n",
    "from keras.layers import Normalization, Dense, Conv2D, Dropout, BatchNormalization, ReLU\n",
    "from keras.models import Sequential, Model\n",
    "from keras import Input\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.layers import LeakyReLU, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from skimage.transform import AffineTransform, warp\n",
    "from keras import Sequential, Model\n",
    "from keras.layers import Dense, Conv2D, Reshape, UpSampling2D, \\\n",
    "    BatchNormalization, Activation, Input, LeakyReLU, ZeroPadding2D, Dropout, Flatten, Conv2DTranspose\n",
    "from keras.optimizers import Adam\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from scipy.ndimage import rotate\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Reshape, UpSampling2D, Conv2D, BatchNormalization, Activation, Input, LeakyReLU\n",
    "from keras.initializers import RandomNormal\n",
    "from numpy import expand_dims\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "from numpy.random import randn\n",
    "from numpy.random import randint\n",
    "from keras.datasets.fashion_mnist import load_data\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Conv2DTranspose\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style='darkgrid', palette='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List physical GPUs and set memory growth\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file into a pandas DataFrame\n",
    "df = pd.read_csv('emnist-letters-train.csv', delimiter=',', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={0: 'labels'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['labels'] != -1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "      <th>784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99032</th>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99033</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99035</th>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99036</th>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99037</th>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88800 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       labels  1  2  3  4  5  6  7  8  9  ...  775  776  777  778  779  780  \\\n",
       "0          23  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0   \n",
       "1           7  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0   \n",
       "2          16  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0   \n",
       "3          15  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0   \n",
       "4          23  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0   \n",
       "...       ... .. .. .. .. .. .. .. .. ..  ...  ...  ...  ...  ...  ...  ...   \n",
       "99032      26  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0   \n",
       "99033      23  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0   \n",
       "99035      18  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0   \n",
       "99036      24  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0   \n",
       "99037      19  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0   \n",
       "\n",
       "       781  782  783  784  \n",
       "0        0    0    0    0  \n",
       "1        0    0    0    0  \n",
       "2        0    0    0    0  \n",
       "3        0    0    0    0  \n",
       "4        0    0    0    0  \n",
       "...    ...  ...  ...  ...  \n",
       "99032    0    0    0    0  \n",
       "99033    0    0    0    0  \n",
       "99035    0    0    0    0  \n",
       "99036    0    0    0    0  \n",
       "99037    0    0    0    0  \n",
       "\n",
       "[88800 rows x 785 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the mapping dictionary\n",
    "mapping = {1: 97, 2: 98, 3: 99, 4: 100, 5: 101, 6: 102, 7: 103, 8: 104, 9: 105, \n",
    "           10: 106, 11: 107, 12: 108, 13: 109, 14: 110, 15: 111, 16: 112, 17: 113, \n",
    "           18: 114, 19: 115, 20: 116, 21: 117, 22: 118, 23: 119, 24: 120, 25: 121, \n",
    "           26: 122, 27: 123}\n",
    "\n",
    "        # Map the labels column to its corresponding value\n",
    "df['labels'] = df['labels'].map(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(88800, 28, 28, 1)\n",
      "(88800,)\n"
     ]
    }
   ],
   "source": [
    "# Convert the DataFrame to a NumPy array\n",
    "data = df.to_numpy()\n",
    "\n",
    "# Extract the labels and images from the NumPy array\n",
    "labels = data[:, 0]  # Assuming the first column is the labels\n",
    "images = data[:, 1:]  # The rest are the images\n",
    "\n",
    "# Optionally, you can reshape and normalize the images if needed\n",
    "# For example, if the images are 28x28 pixels\n",
    "images = images.reshape(-1, 28, 28, 1)  # Reshape to (num_samples, 28, 28, 1)\n",
    "# images = images / 255.0  # Normalize to [0, 1]\n",
    "\n",
    "# Convert the mapped labels to characters\n",
    "# mapped_labels = np.vectorize(mapping.get)(labels)\n",
    "# labels = np.vectorize(chr)(mapped_labels)\n",
    "\n",
    "# Now 'images' and 'labels' are NumPy arrays ready for use\n",
    "print(images.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([119, 103, 112, ..., 114, 120, 115], dtype=int64)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (56832, 28, 28, 1)\n",
      "Validation set shape: (14208, 28, 28, 1)\n",
      "Test set shape: (17760, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Validation set shape: {X_val.shape}\")\n",
    "print(f\"Test set shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels = np.unique(y_train)\n",
    "def Show_Images(data,unique_labels,labels):\n",
    "    # Create the plot with sufficient subplots\n",
    "    fig, axes = plt.subplots(3, 9, figsize=(20, 8))  # Adjusted to 3 rows and 9 columns for demonstration\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for label, ax in zip(unique_labels, axes):\n",
    "        # Select the first image for each unique label\n",
    "        idx = np.where(labels == label)[0][0]\n",
    "        image = data[idx].reshape(28, 28)\n",
    "        \n",
    "        # Display the image\n",
    "        ax.imshow(image, cmap='gray')\n",
    "        ax.set_title(f'Label: {label}')\n",
    "        ax.axis('off')\n",
    "\n",
    "    # Hide any remaining empty subplots (if any)\n",
    "    for ax in axes[len(unique_labels):]:\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Show_Images(X_train,unique_labels,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images_per_label_Aug_sheer(images, labels, num_images_per_label=5):\n",
    "    unique_labels = np.unique(labels)\n",
    "    \n",
    "    # Create the plot with sufficient subplots\n",
    "    fig, axes = plt.subplots(len(unique_labels), num_images_per_label * 2, figsize=(20, len(unique_labels) * 2))\n",
    "    axes = axes.flatten()  # Flatten the 2D array of axes to easily iterate\n",
    "\n",
    "    # Counter for current axis\n",
    "    ax_index = 0\n",
    "\n",
    "    for label in unique_labels:\n",
    "        # Filter images for the current label\n",
    "        indices = np.where(labels == label)[0]\n",
    "        \n",
    "        # Loop through up to num_images_per_label images for the current label\n",
    "        for i in range(min(num_images_per_label, len(indices))):\n",
    "            image = images[indices[i]].reshape(28, 28)\n",
    "            \n",
    "            # Display the original image\n",
    "            axes[ax_index].imshow(image, cmap='gray')\n",
    "            axes[ax_index].set_title(f'Label: {label}')\n",
    "            axes[ax_index].axis('off')\n",
    "            ax_index += 1\n",
    "\n",
    "            if ax_index >= len(axes):\n",
    "                break\n",
    "\n",
    "        for i in range(min(num_images_per_label, len(indices))):\n",
    "            image = images[indices[i]].reshape(28, 28)\n",
    "\n",
    "            # Rotate the image by 15 degrees\n",
    "            rotated_image = rotate(image, -90, reshape=False)\n",
    "            \n",
    "            # Apply shear transformation\n",
    "            # shear_transform = AffineTransform(shear=0.2)\n",
    "            # sheared_image = warp(rotated_image, shear_transform.inverse, mode='wrap')\n",
    "            flipped_image = np.fliplr(rotated_image)\n",
    "\n",
    "            # Display the augmented image\n",
    "            axes[ax_index].imshow(flipped_image, cmap='gray')\n",
    "            axes[ax_index].set_title(f'Labels Augmented: {label}')\n",
    "            axes[ax_index].axis('off')\n",
    "            ax_index += 1\n",
    "\n",
    "            if ax_index >= len(axes):\n",
    "                break\n",
    "\n",
    "    # Hide any remaining empty subplots (if any)\n",
    "    for ax in axes[ax_index:]:\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_images_per_label_Aug_sheer(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_images = []\n",
    "for image in images:\n",
    "    rotated_image = rotate(image, 90, reshape=False)\n",
    "    flipped_image = np.flipud(rotated_image)  # Flip vertically\n",
    "    augmented_images.append(flipped_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_images = np.array(augmented_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Augmented set shape: (84360, 28, 28, 1)\n",
      "Test Augmented set shape: (17760, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# Split the data into train and test sets\n",
    "X_train_aug, X_test_aug, y_train_aug, y_test_aug = train_test_split(augmented_images, labels, test_size=0.05, random_state=42)\n",
    "print(f\"Training Augmented set shape: {X_train_aug.shape}\")\n",
    "print(f\"Test Augmented set shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented Shape : (88800, 28, 28, 1)\n",
      "Label Shape : (88800,)\n"
     ]
    }
   ],
   "source": [
    "print(f'Augmented Shape : {augmented_images.shape}')\n",
    "print(f'Label Shape : {labels.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class DCGAN():\n",
    "#     def __init__(self, rows, cols, channels, z = 100):\n",
    "#         # Input shape\n",
    "#         self.img_rows = rows\n",
    "#         self.img_cols = cols\n",
    "#         self.channels = channels\n",
    "#         self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "#         self.latent_dim = z\n",
    "#         optimizer = Adam(0.0001, 0.7)\n",
    "#         self.discriminator = self.build_discriminator()\n",
    "#         self.discriminator.compile(loss='binary_crossentropy', optimizer=optimizer,metrics=['accuracy'])\n",
    "#         self.generator = self.build_generator()\n",
    "#         z = Input(shape=(self.latent_dim,))\n",
    "#         img = self.generator(z)\n",
    "#         self.discriminator.trainable = False\n",
    "#         valid = self.discriminator(img)\n",
    "#         self.combined = Model(z, valid)\n",
    "#         self.combined.compile(loss='binary_crossentropy',optimizer=optimizer)\n",
    "    \n",
    "#     def train(self, epochs, batch_size=256, save_interval=50):\n",
    "#         # Load the dataset\n",
    "#         X_train = X_train_aug\n",
    "#         # Rescale -1 to 1\n",
    "#         X_train = X_train / 255\n",
    "#         X_train = np.expand_dims(X_train, axis=3)\n",
    "#         # Adversarial ground truths\n",
    "#         valid = np.ones((batch_size, 1))\n",
    "#         fake = np.zeros((batch_size, 1))\n",
    "#         for epoch in range(epochs):\n",
    "#             idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "#             imgs = X_train[idx]\n",
    "#             # Sample noise and generate a batch of new images\n",
    "#             noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "#             gen_imgs = self.generator.predict(noise)\n",
    "#             # Train the discriminator (real classified as ones\n",
    "#             # and generated as zeros)\n",
    "#             d_loss_real = self.discriminator.train_on_batch(imgs, valid)\n",
    "#             d_loss_fake = self.discriminator.train_on_batch(gen_imgs, fake)\n",
    "#             d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "#             # ---------------------\n",
    "#             # Train Generator\n",
    "#             # ---------------------\n",
    "#             # Train the generator (wants discriminator to mistake\n",
    "#             # images as real)\n",
    "#             g_loss = self.combined.train_on_batch(noise, valid)\n",
    "#             # Plot the progress\n",
    "#             print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
    "\n",
    "#             # If at save interval => save generated image samples\n",
    "#             if epoch % save_interval == 0:\n",
    "#                 self.save_imgs(epoch)\n",
    "\n",
    "#     def build_discriminator(self):\n",
    "#         model = Sequential()\n",
    "#         model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=self.img_shape, padding=\"same\"))\n",
    "#         model.add(LeakyReLU(alpha=0.2))\n",
    "#         model.add(Dropout(0.25))\n",
    "#         model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "#         model.add(ZeroPadding2D(padding=((0,1),(0,1))))\n",
    "#         model.add(BatchNormalization(momentum=0.8))\n",
    "#         model.add(LeakyReLU(alpha=0.2))\n",
    "#         model.add(Dropout(0.25))\n",
    "#         model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "#         model.add(BatchNormalization(momentum=0.8))\n",
    "#         model.add(LeakyReLU(alpha=0.2))\n",
    "#         model.add(Dropout(0.25))\n",
    "#         model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n",
    "#         model.add(BatchNormalization(momentum=0.8))\n",
    "#         model.add(LeakyReLU(alpha=0.2))\n",
    "#         model.add(Dropout(0.25))\n",
    "#         model.add(Conv2D(528, kernel_size=3, strides=1, padding=\"same\"))\n",
    "#         model.add(BatchNormalization(momentum=0.8))\n",
    "#         model.add(LeakyReLU(alpha=0.2))\n",
    "#         model.add(Dropout(0.25))\n",
    "#         model.add(Conv2D(1024, kernel_size=3, strides=1, padding=\"same\"))\n",
    "#         model.add(BatchNormalization(momentum=0.8))\n",
    "#         model.add(LeakyReLU(alpha=0.2))\n",
    "#         model.add(Dropout(0.25))\n",
    "#         model.add(Flatten())\n",
    "#         model.add(Dense(1, activation='sigmoid'))\n",
    "#         model.summary()\n",
    "#         img = Input(shape=self.img_shape)\n",
    "#         validity = model(img)\n",
    "#         return Model(img, validity)\n",
    "    \n",
    "#     def build_generator(self):\n",
    "#         model = Sequential()\n",
    "#         model.add(Dense(128 * 7 * 7, activation=\"relu\", input_dim=self.latent_dim))\n",
    "#         model.add(Reshape((7, 7, 128)))\n",
    "#         model.add(UpSampling2D())\n",
    "#         model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
    "#         model.add(BatchNormalization(momentum=0.8))\n",
    "#         model.add(Activation(\"relu\"))\n",
    "#         model.add(UpSampling2D())\n",
    "#         model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
    "#         model.add(BatchNormalization(momentum=0.8))\n",
    "#         model.add(Activation(\"relu\"))\n",
    "#         model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
    "#         model.add(BatchNormalization(momentum=0.8))\n",
    "#         model.add(Activation(\"relu\"))\n",
    "#         model.add(Conv2D(self.channels, kernel_size=3, padding=\"same\"))\n",
    "#         model.add(Activation(\"tanh\"))\n",
    "#         model.summary()\n",
    "#         noise = Input(shape=(self.latent_dim,))\n",
    "#         img = model(noise)\n",
    "#         return Model(noise, img)\n",
    "    \n",
    "#     def save_imgs(self, epoch):\n",
    "#         r, c = 5, 5\n",
    "#         noise = np.random.normal(0, 1, (r * c, self.latent_dim))\n",
    "#         gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "#         # Rescale images 0 - 1\n",
    "#         # gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "#         fig, axs = plt.subplots(r, c)\n",
    "#         cnt = 0\n",
    "#         for i in range(r):\n",
    "#             for j in range(c):\n",
    "#                 axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
    "#                 axs[i,j].axis('off')\n",
    "#                 cnt += 1\n",
    "#         os.makedirs('generated_mnist', exist_ok=True)\n",
    "#         fig.savefig(\"generated_mnist/dcgan_mnist_improved_{:d}.png\".format(epoch))\n",
    "#         plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set image dimensions\n",
    "# img_rows, img_cols, channels = 28, 28, 1\n",
    "\n",
    "# # Instantiate and train the DCGAN\n",
    "# dcgan = DCGAN(img_rows, img_cols, channels)\n",
    "# dcgan.train(epochs=10000, batch_size=256, save_interval=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class DCGAN():\n",
    "\n",
    "#     # this is the function to build the generator neural network\n",
    "#     def build_generator(self):\n",
    "#         model = Sequential(name='Generator')\n",
    "#         model.add(Dense(128 * 7 * 7, activation=\"relu\", input_dim=self.latent_dim)) # connect the input to dense layer\n",
    "#         model.add(Reshape((7, 7, 128)))\n",
    "#         # upsample from 7*7 to 14*14\n",
    "#         model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
    "#         model.add(LeakyReLU(alpha=0.2))\n",
    "#         # upsample to 28x28\n",
    "#         model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
    "#         model.add(LeakyReLU(alpha=0.2))\n",
    "#         model.add(Conv2D(self.channels, kernel_size=7, padding=\"same\", activation='sigmoid'))\n",
    "#         model.summary()\n",
    "#         noise = Input(shape=(self.latent_dim,))\n",
    "#         img = model(noise)\n",
    "#         return Model(noise, img)  # the keras Model class groups layers into an object with training and inference features\n",
    "    \n",
    "#     def build_discriminator(self):\n",
    "#         model = Sequential(name='Discriminator')\n",
    "#         model.add(Conv2D(128, kernel_size=3, strides=2, input_shape=self.img_shape, padding=\"same\"))\n",
    "#         model.add(LeakyReLU(alpha=0.2))\n",
    "#         model.add(Dropout(0.4))\n",
    "#         model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "#         model.add(LeakyReLU(alpha=0.2))\n",
    "#         model.add(Dropout(0.4))\n",
    "#         model.add(Flatten())\n",
    "#         model.add(Dense(1, activation='sigmoid'))\n",
    "#         model.summary()\n",
    "#         img = Input(shape=self.img_shape)\n",
    "#         validity = model(img)\n",
    "#         return Model(img, validity)\n",
    "    \n",
    "#     def __init__(self, rows, cols, channels, z = 100):\n",
    "#         # Input shape\n",
    "#         self.img_rows = rows  # generated image height\n",
    "#         self.img_cols = cols  # generated image width\n",
    "#         self.channels = channels  # generated image channel\n",
    "#         self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "#         self.latent_dim = z  # the input is 1-D vector of noise\n",
    "#         # Reduce learning rate from 0.001 to 0.0002, and beta1 from 0.9 to 0.5, which can stablize training and reduce oscillation\n",
    "#         optimizer = Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "#         # Build and compile the discriminator\n",
    "#         self.discriminator = self.build_discriminator()\n",
    "#         self.discriminator.compile(loss='binary_crossentropy',\n",
    "#             optimizer=optimizer,\n",
    "#             metrics=['accuracy'])\n",
    "#         # Build the generator\n",
    "#         self.generator = self.build_generator()\n",
    "#         # The generator takes noise as input and generates images\n",
    "#         z = Input(shape=(self.latent_dim,))\n",
    "#         img = self.generator(z)\n",
    "#         # For the combined model we will only train the generator\n",
    "#         self.discriminator.trainable = False\n",
    "#         # The discriminator takes generated images as input and determines validity\n",
    "#         valid = self.discriminator(img)\n",
    "#         # The combined model (stacked generator and discriminator)\n",
    "#         # Trains the generator to fool the discriminator\n",
    "#         self.combined = Model(z, valid)\n",
    "#         self.combined.compile(loss='binary_crossentropy',\n",
    "#             optimizer=optimizer)\n",
    "    \n",
    "#     def train(self, epochs, batch_size=128, save_interval=50):\n",
    "#         # Load the dataset\n",
    "#         # Split the data into train and test sets\n",
    "#         X_train, X_test, y_train, y_test = train_test_split(augmented_images, labels, test_size=0.2, random_state=42)\n",
    "#         # Rescale 0 to 1\n",
    "#         X_train = X_train / 255\n",
    "#         X_train = np.expand_dims(X_train, axis=3)\n",
    "#         # Adversarial ground truths\n",
    "#         valid = np.ones((batch_size, 1))\n",
    "#         fake = np.zeros((batch_size, 1))\n",
    "#         for epoch in range(epochs):\n",
    "#             # ---------------------\n",
    "#             # Train Discriminator\n",
    "#             # ---------------------\n",
    "#             # Select a random half of images\n",
    "#             idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "#             imgs = X_train[idx]\n",
    "#             # Sample noise and generate a batch of new images\n",
    "#             noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "#             gen_imgs = self.generator.predict(noise)\n",
    "#             # Train the discriminator (it classify real images as 1 and generated images as 0)\n",
    "#             d_loss_real = self.discriminator.train_on_batch(imgs, valid)\n",
    "#             d_loss_fake = self.discriminator.train_on_batch(gen_imgs, fake)\n",
    "#             d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "#             # Train the generator (it wants discriminator to predict generated images as 1)\n",
    "#             g_loss = self.combined.train_on_batch(noise, valid)\n",
    "#             # Plot the progress\n",
    "#             print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
    "            \n",
    "#             # If at save interval => save generated image samples\n",
    "#             if epoch % save_interval == 0:\n",
    "#                 self.save_imgs(epoch)\n",
    "    \n",
    "#     def save_imgs(self, epoch):\n",
    "#         r, c = 5, 5\n",
    "#         noise = np.random.normal(0, 1, (r * c, self.latent_dim))\n",
    "#         gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "#         # Rescale images 0 - 1\n",
    "#         # gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "#         fig, axs = plt.subplots(r, c)\n",
    "#         cnt = 0\n",
    "#         for i in range(r):\n",
    "#             for j in range(c):\n",
    "#                 axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
    "#                 axs[i,j].axis('off')\n",
    "#                 cnt += 1\n",
    "#         os.makedirs('generated_mnist', exist_ok=True)\n",
    "#         fig.savefig(\"generated_mnist/dcgan_mnist_{:d}.png\".format(epoch))\n",
    "#         plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set image dimensions\n",
    "# img_rows, img_cols, channels = 28, 28, 1\n",
    "\n",
    "# # Instantiate and train the DCGAN\n",
    "# dcgan = DCGAN(img_rows, img_cols, channels)\n",
    "# dcgan.train(epochs=10000, batch_size=256, save_interval=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_conditional_generator(z_dim=100, output_shape=(88800, 3, 1),\n",
    "                                num_classes=3, verbose=True):\n",
    "    noise = Input(shape=(z_dim,))\n",
    "    label = Input(shape=(1,), dtype='int32')\n",
    "    label_embedding = Flatten()(Embedding(num_classes, z_dim)(label))\n",
    "    model_input = multiply([noise, label_embedding])\n",
    "\n",
    "    mlp = Dense(256, input_dim=z_dim)(model_input)\n",
    "    mlp = LeakyReLU(alpha=0.2)(mlp)\n",
    "    mlp = BatchNormalization(momentum=0.8)(mlp)\n",
    "    mlp = Dense(512)(mlp)\n",
    "    mlp = LeakyReLU(alpha=0.2)(mlp)\n",
    "    mlp = Dense(1024)(mlp)\n",
    "    mlp = LeakyReLU(alpha=0.2)(mlp)\n",
    "    mlp = BatchNormalization(momentum=0.8)(mlp)\n",
    "    mlp = Dense(np.prod(output_shape), activation='tanh')(mlp)\n",
    "    mlp = Reshape(output_shape)(mlp)\n",
    "\n",
    "    model = Model([noise, label], mlp)\n",
    "\n",
    "    if verbose:\n",
    "        model.summary()\n",
    "    return model\n",
    "\n",
    "\n",
    "def build_conditional_discriminator(input_shape=(1200, 3, 1),\n",
    "                                    num_classes=3, verbose=True):\n",
    "    img = Input(shape=input_shape)\n",
    "    flat_img = Flatten()(img)\n",
    "\n",
    "    label = Input(shape=(1,), dtype='int32')\n",
    "    label_embedding = Flatten()(Embedding(num_classes,\n",
    "                                          np.prod(input_shape))(label))\n",
    "\n",
    "    model_input = multiply([flat_img, label_embedding])\n",
    "\n",
    "    mlp = Dense(512, input_dim=np.prod(input_shape))(model_input)\n",
    "    mlp = LeakyReLU(alpha=0.2)(mlp)\n",
    "    mlp = Dense(512)(mlp)\n",
    "    mlp = LeakyReLU(alpha=0.2)(mlp)\n",
    "    mlp = Dropout(0.4)(mlp)\n",
    "    mlp = Dense(512)(mlp)\n",
    "    mlp = LeakyReLU(alpha=0.2)(mlp)\n",
    "    mlp = Dropout(0.4)(mlp)\n",
    "    mlp = Dense(1, activation='sigmoid')(mlp)\n",
    "\n",
    "    model = Model([img, label], mlp)\n",
    "\n",
    "    if verbose:\n",
    "        model.summary()\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def build_critic(input_shape=(1200, 3, 1), verbose=True):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape))\n",
    "    model.add(Conv2D(16, kernel_size=3, strides=2, padding=\"same\"))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(32, kernel_size=3, strides=2, padding=\"same\"))\n",
    "    model.add(ZeroPadding2D(padding=((0, 1), (0, 1))))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(128, kernel_size=3, strides=1, padding=\"same\"))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    if verbose:\n",
    "        model.summary()\n",
    "    return model\n",
    "\n",
    "\n",
    "def wasserstein_loss(y_true, y_pred):\n",
    "    return K.mean(y_true * y_pred)\n",
    "\n",
    "\n",
    "\n",
    "def train(generator=None,discriminator=None,gan_model=None,\n",
    "          epochs=1000, batch_size=128, sample_interval=50,\n",
    "          z_dim=100):\n",
    "    labels = data[:, 0]  # Assuming the first column is the labels\n",
    "    # Load MNIST train samples\n",
    "    X_train, X_test_aug, y_train, y_test_aug = train_test_split(augmented_images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Rescale -1 to 1\n",
    "    X_train = X_train / 127.5 - 1\n",
    "    X_train = np.expand_dims(X_train, axis=3)\n",
    "    y_train = y_train.reshape(-1, 1)\n",
    "\n",
    "    # Prepare GAN output labels\n",
    "    real_y = np.ones((batch_size, 1))\n",
    "    fake_y = np.zeros((batch_size, 1))\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # train disriminator\n",
    "        # pick random real samples from X_train\n",
    "        idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "        real_imgs, labels = X_train[idx], y_train[idx]\n",
    "\n",
    "        # pick random noise samples (z) from a normal distribution\n",
    "        noise = np.random.normal(0, 1, (batch_size, z_dim))\n",
    "        # use generator model to generate output samples\n",
    "        fake_imgs = generator.predict([noise, labels])\n",
    "\n",
    "        # calculate discriminator loss on real samples\n",
    "        disc_loss_real = discriminator.train_on_batch([real_imgs, labels], real_y)\n",
    "        \n",
    "        # calculate discriminator loss on fake samples\n",
    "        disc_loss_fake = discriminator.train_on_batch([fake_imgs, labels], fake_y)\n",
    "        \n",
    "        # overall discriminator loss\n",
    "        discriminator_loss = 0.5 * np.add(disc_loss_real, disc_loss_fake)\n",
    "        \n",
    "        # train generator\n",
    "        # pick random noise samples (z) from a normal distribution\n",
    "        noise = np.random.normal(0, 1, (batch_size, z_dim))\n",
    "        \n",
    "        # pick random labels for conditioning\n",
    "        sampled_labels = np.random.randint(0, 10, batch_size).reshape(-1, 1)\n",
    "\n",
    "        # use trained discriminator to improve generator\n",
    "        gen_loss = gan_model.train_on_batch([noise, sampled_labels], real_y)\n",
    "\n",
    "        # training updates\n",
    "        print (\"%d [Discriminator loss: %f, acc.: %.2f%%] [Generator loss: %f]\" % (epoch, \n",
    "                                                                                   discriminator_loss[0], \n",
    "                                                                                   100*discriminator_loss[1], \n",
    "                                                                                   gen_loss))\n",
    "\n",
    "        # If at save interval => save generated image samples\n",
    "        if epoch % sample_interval == 0:\n",
    "            sample_images(epoch,generator)\n",
    "\n",
    "\n",
    "def sample_images(epoch, generator, z_dim=100,\n",
    "                  save_output=True,\n",
    "                  output_dir=\"images\"):\n",
    "\n",
    "    # get label if conditional generator is active\n",
    "    model_type = 'cgan' if isinstance(generator.input_shape, list) else 'others'\n",
    "\n",
    "    if model_type == 'cgan':\n",
    "        r, c = 2, 5\n",
    "        noise = np.random.normal(0, 1, (r * c, z_dim))\n",
    "        sampled_labels = np.arange(0,2).reshape(-1, 1)\n",
    "        gen_imgs = generator.predict([noise, sampled_labels])\n",
    "    else:\n",
    "        r, c = 5, 5\n",
    "        noise = np.random.normal(0, 1, (r * c, z_dim))\n",
    "        gen_imgs = generator.predict(noise)\n",
    "\n",
    "    # Rescale images 0 - 1\n",
    "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "    # get output shape\n",
    "    output_shape = len(generator.output_shape)\n",
    "\n",
    "    fig, axs = plt.subplots(r, c)\n",
    "    cnt = 0\n",
    "    for i in range(r):\n",
    "        for j in range(c):\n",
    "            if output_shape == 3:\n",
    "                axs[i, j].imshow(gen_imgs[cnt, :, :], cmap='gray')\n",
    "            else:\n",
    "                axs[i, j].imshow(gen_imgs[cnt, :, :, 0], cmap='gray')\n",
    "            if model_type == 'cgan':\n",
    "                axs[i, j].set_title(\"Label: %d\" % sampled_labels[cnt])\n",
    "            axs[i, j].axis('off')\n",
    "            cnt += 1\n",
    "    plt.show()\n",
    "    if save_output:\n",
    "        fig.savefig(\"{}/{}.png\".format(output_dir, epoch))\n",
    "    plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_11\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_25 (InputLayer)          [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " input_24 (InputLayer)          [(None, 1200, 3, 1)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " embedding_9 (Embedding)        (None, 1, 3600)      10800       ['input_25[0][0]']               \n",
      "                                                                                                  \n",
      " flatten_19 (Flatten)           (None, 3600)         0           ['input_24[0][0]']               \n",
      "                                                                                                  \n",
      " flatten_20 (Flatten)           (None, 3600)         0           ['embedding_9[0][0]']            \n",
      "                                                                                                  \n",
      " multiply_8 (Multiply)          (None, 3600)         0           ['flatten_19[0][0]',             \n",
      "                                                                  'flatten_20[0][0]']             \n",
      "                                                                                                  \n",
      " dense_53 (Dense)               (None, 512)          1843712     ['multiply_8[0][0]']             \n",
      "                                                                                                  \n",
      " leaky_re_lu_39 (LeakyReLU)     (None, 512)          0           ['dense_53[0][0]']               \n",
      "                                                                                                  \n",
      " dense_54 (Dense)               (None, 512)          262656      ['leaky_re_lu_39[0][0]']         \n",
      "                                                                                                  \n",
      " leaky_re_lu_40 (LeakyReLU)     (None, 512)          0           ['dense_54[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 512)          0           ['leaky_re_lu_40[0][0]']         \n",
      "                                                                                                  \n",
      " dense_55 (Dense)               (None, 512)          262656      ['dropout_8[0][0]']              \n",
      "                                                                                                  \n",
      " leaky_re_lu_41 (LeakyReLU)     (None, 512)          0           ['dense_55[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_9 (Dropout)            (None, 512)          0           ['leaky_re_lu_41[0][0]']         \n",
      "                                                                                                  \n",
      " dense_56 (Dense)               (None, 1)            513         ['dropout_9[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,380,337\n",
      "Trainable params: 2,380,337\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "{{function_node __wrapped__Mul_device_/job:localhost/replica:0/task:0/device:GPU:0}} failed to allocate memory [Op:Mul]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[148], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m discriminator \u001b[38;5;241m=\u001b[39m build_conditional_discriminator()\n\u001b[0;32m      5\u001b[0m discriminator\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39mAdam(\u001b[38;5;241m0.0002\u001b[39m, \u001b[38;5;241m0.5\u001b[39m), metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m----> 6\u001b[0m generator \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_conditional_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild_generator\u001b[39m(z_dim):\n\u001b[0;32m      9\u001b[0m     model \u001b[38;5;241m=\u001b[39m Sequential()\n",
      "Cell \u001b[1;32mIn[147], line 16\u001b[0m, in \u001b[0;36mbuild_conditional_generator\u001b[1;34m(z_dim, output_shape, num_classes, verbose)\u001b[0m\n\u001b[0;32m     14\u001b[0m mlp \u001b[38;5;241m=\u001b[39m LeakyReLU(alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m)(mlp)\n\u001b[0;32m     15\u001b[0m mlp \u001b[38;5;241m=\u001b[39m BatchNormalization(momentum\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.8\u001b[39m)(mlp)\n\u001b[1;32m---> 16\u001b[0m mlp \u001b[38;5;241m=\u001b[39m \u001b[43mDense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprod\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_shape\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtanh\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmlp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m mlp \u001b[38;5;241m=\u001b[39m Reshape(output_shape)(mlp)\n\u001b[0;32m     19\u001b[0m model \u001b[38;5;241m=\u001b[39m Model([noise, label], mlp)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\keras\\backend.py:2100\u001b[0m, in \u001b[0;36mRandomGenerator.random_uniform\u001b[1;34m(self, shape, minval, maxval, dtype, nonce)\u001b[0m\n\u001b[0;32m   2098\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nonce:\n\u001b[0;32m   2099\u001b[0m         seed \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mstateless_fold_in(seed, nonce)\n\u001b[1;32m-> 2100\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstateless_uniform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2101\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2102\u001b[0m \u001b[43m        \u001b[49m\u001b[43mminval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mminval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2103\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaxval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaxval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2104\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2105\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2106\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2107\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39muniform(\n\u001b[0;32m   2108\u001b[0m     shape\u001b[38;5;241m=\u001b[39mshape,\n\u001b[0;32m   2109\u001b[0m     minval\u001b[38;5;241m=\u001b[39mminval,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2112\u001b[0m     seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_legacy_seed(),\n\u001b[0;32m   2113\u001b[0m )\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: {{function_node __wrapped__Mul_device_/job:localhost/replica:0/task:0/device:GPU:0}} failed to allocate memory [Op:Mul]"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import multiply\n",
    "#Code snippet for creating and compiling the cGAN model\n",
    "discriminator = build_conditional_discriminator()\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=Adam(0.0002, 0.5), metrics=['accuracy'])\n",
    "generator = build_conditional_generator()\n",
    "\n",
    "def build_generator(z_dim):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(256, input_dim=z_dim))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Dense(512))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Dense(1024))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Dense(28 * 28 * 1, activation='tanh'))\n",
    "    model.add(Reshape((28, 28, 1)))\n",
    "\n",
    "    return model\n",
    "\n",
    "def build_discriminator():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Flatten(input_shape=(28, 28, 1)))\n",
    "    model.add(Dense(512))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dense(256))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    return model\n",
    "\n",
    "def build_gan(generator, discriminator):\n",
    "    z = Input(shape=(100,))\n",
    "    img = generator(z)\n",
    "    discriminator.trainable = False\n",
    "    valid = discriminator(img)\n",
    "    \n",
    "    combined = Model(z, valid)\n",
    "    combined.compile(loss='binary_crossentropy', optimizer=Adam(0.0002, 0.5))\n",
    "    \n",
    "    return combined\n",
    "\n",
    "# Create the models\n",
    "generator = build_generator(100)\n",
    "discriminator = build_discriminator()\n",
    "\n",
    "# Compile the discriminator\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=Adam(0.0002, 0.5), metrics=['accuracy'])\n",
    "\n",
    "# Create and compile the GAN model\n",
    "gan_model = build_gan(generator, discriminator)\n",
    "\n",
    "# Code snippet for training the cGAN\n",
    "train(generator, discriminator, gan_model, epochs=20000, batch_size=32, sample_interval=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
